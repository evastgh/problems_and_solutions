Wednesday June 3rd

6 - Biomedical Voice Measurement of Parkinson's Disease
HUNTER, SAMUEL / LI, MEGAN / QIAN, YUXIN / WHITE, THOMAS / XIE, GRANT
good comparison of different test/test ratio
good on providing confusion table
(Grant) dataset & least square (?)
the data description can be longer (not sure if what the attributes come from)
why not explain what sensitivity and specificity mean?
(Yuxin) fisher discriminant & generative model
not capturing difference between fisher discriminant and generative model (#variables)
good cons analysis
(Megan) logistic regression
good analysis on what features are important
good points in cons
(Thomas) feed-forward NN
speaks too fast XD
should mention activation function
good work on different # of layers
good pros & cons analysis
(Sam) K-means clustering
good speech
how are the two arguments plotted selected?
good point on not real-time update with new data point
love the implementation difficulty 

5 people
50/50 satisfying all expectations

4 - Garbage Classification
LIU, JERRY / MILLER, LANDON / PERRY, TRISTAN / XUE, YIQI

(Landon) dataset
Great Zoom virtual background of the blue sky
(Tristan) application of problem, image preprocessing
it's a "third order tensor"
(Yiqi) algorithm overview
independence of each feature?!?!??! -> later mentioned the correlation with adjacent pixels, good to point this out.
(Jiarui) logistic regression
should use one slide for numerical method
(Landon) CNN
good presentation but speaks too fast
(Tristan) accuracy rate
(Yiqi, Jiarui, Landon?) pros and cons


4 people
45/50 satisfying most expectations (the bayes model doesnt make sense)

(Landon: how does the CNN handle RGB value?)


7 - Titanic Survival Data Analysis
ADKISSON, PAUL / DHARNE, ASHWIN / NGUN, WAI YIN / WANG, ZITIAN

(Zitian) intro, logistic regression
speaks too fast!!!
good PCA for exploring linear separability
good work with grid search parameters
(Paul) LDA
how is this generative...
good showing confusion chart
(Ashwin) neural network 
very good analysis on correlation of different features and survival
showing good understand (e.g. entropy is equivalent to MLE)
good cross validation
(Wai yin) random forest classifier
bonus point on using new algorithm!

45/50 using categorical variables...

2 - Predicting & Optimizing Wave Energy Conversion
LARSSON, OSKAR / NAMPEERA, CLAIRE / SINHA, ARUSHI / TRIFUNOVIC, MARLON

(Arushi) intro, dataset
bonus point (3) for good presentation skills and beautiful slides!
(Claire)
should shoe 80/20 data/test on slide
don't quite follow the beta check
(Marlon) neural network
good point on drop out for avoiding overfitting
good iterative work
good analysis of different hyperparameters
good work on GPU lol
(Claire) graphing the error
I fucking cannot understand ausie accent. the worst.
Should provide explanation of the graph
(Oskar) graphing the error, cross-testing
(Arushi, Oskar) conclusion

is Marlon doing all the work...?

4 people
50/50 satisfying all expectations: presenting novel work that expands to understanding the dataset
+2 for GPU

10 - SMS Spam Classification
ZHONG, SHAN

good work on combining datasets!
good work on frequency analysis!
presentation really too long......
good comparison on PCA/SVD

1 person
60/50 with only one member, the amount of work demonstrated is exceptional!


Friday June 5th

3 - MNIST Image Recognition
CHEN, JUNFU / CHI, XIAOYANG / CUI, TIANA / LIU, TIANQI / ZHAO, BRYAN

a little technical difficulty here...
(Tiana) intro, reshaping+normalizing
data set comes with training and testing separation
good point on continuity
(Tianqi) 2-layer NN, evaluation
good showcasing of code
good showcasing of elbow point
(Xiaoyang) more epochs, 3-layer NN
good analysis on crossing point of train_accuracy & test_accuracy
(Junfu) CNN, varying number of layers
good job comparing plain 2-layer NN and CNN!
no explanation on maxpooling :(
(Bryan) overfitting: batch normalization, drop out rate
good intro on BatchNorm and Dropout
good point on trade-off
(Tiana) unsupervised learning: K-means clustering
interesting use of K-means clustering
good presentation
(Tianqi) model comparison, testing new inputs
good consideration on runtime
interesting test on hand written digits themselves

50/50 satisfying all expectation: good in-depth exploration of different NN techniques

(Junfu: how did they decide how to add more tools into CNN?)

8 - Modeling COVID-19 with Machine Learning Methods (SIR Modeling)
CLEMENT, AIDAN / DIAZ, EDUARDO / MORRISON, ELIZABETH / SIKKA, SIDHDHARTH / ZHANG, CHUNLI

Sidh: intro
good presentation on the background
Elizabeth: dataset (WHO), cleanup
confirmed recovered death
good pointing out on self-reporting numbers
good laying out of assumptions
Aidan: SIR model
good presentation on SIR model diff. eq.
(upon request of explanation of I model) Sidh: SIR model
Aidan: regression & parameters
good analysis of the numerical effect of gamma
Eduardo (Eddie): fixed point analysis
finding equilibrium of the diff. eq.
good analysis on equilibrium!
Sidh: testing & results


40/50 not a lot of ML techniques... +7 for novel work

recovery case of CA should be total recovery of US multiplied by percentage of infected in CA
should list the meaning of each variable
presentation is a little long


5 - Facial Expression Classification
LIU, TIANYANG / SUNDAR RAMAN, SUBASH / XIE, KAIZE / YOUNG, ADAM

video recording: no idea who's speaking
bad presentation...

*data set CK+
*data preprocessing
good normalization
good shuffling data for train/test
*logistic regression
good explanation on softmax effect
good analysis on cross entropy
slide a little overwhelming
*decision tree model (tianyang?)
good intro on ASM and splitting feature
does this work on image recognition?!
*CNN, LeNet, ImageNet
unnecessary intro to different net.... but okay.
*ResNet 18
good intro on residual block
*transfer learning

50/50 good amount of work (several in-depth different approaches)
would love to see a table comparing all accuracy rate and training time

9 - Neural Networks and Traffic Flow
AHUJA, RADHIKA / GLYNN, DARRAGH / LEGG, WILLIAM / TANDON, YASH

Yash: intro
(he's a up speaker lol)
very good slides design!
William: math
good presentation skills
using tanh
good walk-through of backpropagation
Darragh: data processing (distance computation)
good point on restricting data to inside Manhattan
using dense layers
good showcasing of code
bonus! Using Google maps API to calculate driving distance
Yash: sample output, future work
good work on separating different time 
good points in future work!

48/50 satisfying most expectations, would love to see more different methods +3 for nice presentation and google maps API

1 - COVID-19 Classification using Convolutional Neural Networks with Chest X-ray Images
CHEN, YOU JEN / CHEN, ZHEXI / GUAN, BRIAN / KERSEY, MARGO

youjen: intro, neural network elements
clear speech & presentation
margo: CNN
good and clear speech & presentation
good point on initial filter
good animation of convolution
good explanation of max pooling
Zhexi: VGG-16
I didn't know there's animated virtual background lol
good showcasing the effect of learning rate
Brian: calculating results, conclusion
good point on precision and recall rate
good point on potential improvements!!

45/50 implemented one single CNN structure and not a lot of comparison
